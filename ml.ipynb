{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abcd\n",
    "collinX1 = loadtxt('data/collin_data_1.txt', delimiter=',')\n",
    "collinY1 = loadtxt('labels/collin_labels_1.txt', delimiter=',')\n",
    "\n",
    "# abcd\n",
    "tianX2 = loadtxt('data/tian_data_2.txt', delimiter=',')\n",
    "tianY2 = loadtxt('labels/tian_labels_2.txt', delimiter=',')\n",
    "\n",
    "# efgh\n",
    "nikolasX3 = loadtxt('data/nikolas_data_3.txt', delimiter=',')\n",
    "nikolasY3 = loadtxt('labels/nikolas_labels_3.txt', delimiter=',')\n",
    "\n",
    "# ijkl\n",
    "tianX4 = loadtxt('data/tian_data_4.txt', delimiter=',')\n",
    "tianY4 = loadtxt('labels/tian_labels_4.txt', delimiter=',')\n",
    "\n",
    "# mnop\n",
    "tianX5 = loadtxt('data/tian_data_5.txt', delimiter=',')\n",
    "tianY5 = loadtxt('labels/tian_labels_5.txt', delimiter=',')\n",
    "\n",
    "# qrst\n",
    "tianX6 = loadtxt('data/tian_data_6.txt', delimiter=',')\n",
    "tianY6 = loadtxt('labels/tian_labels_6.txt', delimiter=',')\n",
    "\n",
    "# uvwxyz\n",
    "tianX7 = loadtxt('data/tian_data_7.txt', delimiter=',')\n",
    "tianY7 = loadtxt('labels/tian_labels_7.txt', delimiter=',')\n",
    "\n",
    "# efgh\n",
    "tianX8 = loadtxt('data/tian_data_8.txt', delimiter=',')\n",
    "tianY8 = loadtxt('labels/tian_labels_8.txt', delimiter=',')\n",
    "\n",
    "# s rest pujt\n",
    "tianX9 = loadtxt('data/tian_data_9.txt', delimiter=',')\n",
    "tianY9 = loadtxt('labels/tian_labels_9.txt', delimiter=',')\n",
    "\n",
    "# drjel\n",
    "tianX10 = loadtxt('data/tian_data_10.txt', delimiter=',')\n",
    "tianY10 = loadtxt('labels/tian_labels_10.txt', delimiter=',')\n",
    "\n",
    "X = np.concatenate((collinX1, tianX2, nikolasX3, tianX4, tianX5, tianX6, tianX7, tianX8, tianX9, tianX10), axis=0)\n",
    "y = np.concatenate((collinY1, tianY2, nikolasY3, tianY4, tianY5, tianY6, tianY7, tianY8, tianY9, tianY10), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0     175\n",
       "4.0     133\n",
       "17.0    129\n",
       "0.0     126\n",
       "11.0    118\n",
       "1.0     115\n",
       "2.0     112\n",
       "7.0      96\n",
       "6.0      93\n",
       "9.0      85\n",
       "5.0      77\n",
       "18.0     72\n",
       "15.0     69\n",
       "19.0     61\n",
       "10.0     59\n",
       "20.0     57\n",
       "16.0     53\n",
       "8.0      52\n",
       "12.0     49\n",
       "23.0     47\n",
       "13.0     45\n",
       "14.0     41\n",
       "22.0     36\n",
       "21.0     34\n",
       "24.0     29\n",
       "25.0     16\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=18, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1979/1979 [==============================] - 0s 120us/step - loss: 3.2145 - accuracy: 0.0520\n",
      "Epoch 2/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 3.0697 - accuracy: 0.1329\n",
      "Epoch 3/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 2.9610 - accuracy: 0.0960\n",
      "Epoch 4/150\n",
      "1979/1979 [==============================] - 0s 89us/step - loss: 2.8616 - accuracy: 0.1157\n",
      "Epoch 5/150\n",
      "1979/1979 [==============================] - 0s 87us/step - loss: 2.7479 - accuracy: 0.2516\n",
      "Epoch 6/150\n",
      "1979/1979 [==============================] - 0s 94us/step - loss: 2.6208 - accuracy: 0.3588\n",
      "Epoch 7/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 2.4829 - accuracy: 0.3997\n",
      "Epoch 8/150\n",
      "1979/1979 [==============================] - 0s 88us/step - loss: 2.3407 - accuracy: 0.4391\n",
      "Epoch 9/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 2.1993 - accuracy: 0.4715\n",
      "Epoch 10/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 2.0625 - accuracy: 0.5472\n",
      "Epoch 11/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 1.9329 - accuracy: 0.5821\n",
      "Epoch 12/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 1.8131 - accuracy: 0.6114\n",
      "Epoch 13/150\n",
      "1979/1979 [==============================] - 0s 92us/step - loss: 1.7040 - accuracy: 0.6296\n",
      "Epoch 14/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 1.6033 - accuracy: 0.6609\n",
      "Epoch 15/150\n",
      "1979/1979 [==============================] - 0s 75us/step - loss: 1.5124 - accuracy: 0.6751\n",
      "Epoch 16/150\n",
      "1979/1979 [==============================] - 0s 102us/step - loss: 1.4316 - accuracy: 0.7029\n",
      "Epoch 17/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 1.3568 - accuracy: 0.7140\n",
      "Epoch 18/150\n",
      "1979/1979 [==============================] - 0s 91us/step - loss: 1.2891 - accuracy: 0.7317\n",
      "Epoch 19/150\n",
      "1979/1979 [==============================] - 0s 87us/step - loss: 1.2268 - accuracy: 0.7559\n",
      "Epoch 20/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 1.1708 - accuracy: 0.7777\n",
      "Epoch 21/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 1.1187 - accuracy: 0.7954\n",
      "Epoch 22/150\n",
      "1979/1979 [==============================] - 0s 89us/step - loss: 1.0699 - accuracy: 0.8146\n",
      "Epoch 23/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 1.0258 - accuracy: 0.8257\n",
      "Epoch 24/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.9849 - accuracy: 0.8348\n",
      "Epoch 25/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.9472 - accuracy: 0.8459\n",
      "Epoch 26/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.9105 - accuracy: 0.8489\n",
      "Epoch 27/150\n",
      "1979/1979 [==============================] - 0s 88us/step - loss: 0.8781 - accuracy: 0.8747\n",
      "Epoch 28/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.8478 - accuracy: 0.8626\n",
      "Epoch 29/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.8176 - accuracy: 0.8782\n",
      "Epoch 30/150\n",
      "1979/1979 [==============================] - 0s 80us/step - loss: 0.7898 - accuracy: 0.8772\n",
      "Epoch 31/150\n",
      "1979/1979 [==============================] - 0s 85us/step - loss: 0.7634 - accuracy: 0.8893\n",
      "Epoch 32/150\n",
      "1979/1979 [==============================] - 0s 80us/step - loss: 0.7389 - accuracy: 0.8944\n",
      "Epoch 33/150\n",
      "1979/1979 [==============================] - 0s 90us/step - loss: 0.7166 - accuracy: 0.8843\n",
      "Epoch 34/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 0.6943 - accuracy: 0.9035\n",
      "Epoch 35/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.6738 - accuracy: 0.9030\n",
      "Epoch 36/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 0.6554 - accuracy: 0.9035\n",
      "Epoch 37/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.6357 - accuracy: 0.9040\n",
      "Epoch 38/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.6183 - accuracy: 0.9101\n",
      "Epoch 39/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.6013 - accuracy: 0.9090\n",
      "Epoch 40/150\n",
      "1979/1979 [==============================] - 0s 78us/step - loss: 0.5877 - accuracy: 0.9065\n",
      "Epoch 41/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.5720 - accuracy: 0.9141\n",
      "Epoch 42/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.5578 - accuracy: 0.9151\n",
      "Epoch 43/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.5449 - accuracy: 0.9166\n",
      "Epoch 44/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.5318 - accuracy: 0.9171\n",
      "Epoch 45/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.5194 - accuracy: 0.9212\n",
      "Epoch 46/150\n",
      "1979/1979 [==============================] - 0s 92us/step - loss: 0.5074 - accuracy: 0.9217\n",
      "Epoch 47/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.4969 - accuracy: 0.9232\n",
      "Epoch 48/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.4865 - accuracy: 0.9242\n",
      "Epoch 49/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.4753 - accuracy: 0.9267\n",
      "Epoch 50/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.4652 - accuracy: 0.9267\n",
      "Epoch 51/150\n",
      "1979/1979 [==============================] - 0s 76us/step - loss: 0.4571 - accuracy: 0.9282\n",
      "Epoch 52/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.4477 - accuracy: 0.9323\n",
      "Epoch 53/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 0.4389 - accuracy: 0.9308\n",
      "Epoch 54/150\n",
      "1979/1979 [==============================] - 0s 75us/step - loss: 0.4301 - accuracy: 0.9323\n",
      "Epoch 55/150\n",
      "1979/1979 [==============================] - 0s 78us/step - loss: 0.4219 - accuracy: 0.9399\n",
      "Epoch 56/150\n",
      "1979/1979 [==============================] - 0s 74us/step - loss: 0.4144 - accuracy: 0.9384\n",
      "Epoch 57/150\n",
      "1979/1979 [==============================] - 0s 76us/step - loss: 0.4077 - accuracy: 0.9363\n",
      "Epoch 58/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.4007 - accuracy: 0.9414\n",
      "Epoch 59/150\n",
      "1979/1979 [==============================] - 0s 76us/step - loss: 0.3930 - accuracy: 0.9434\n",
      "Epoch 60/150\n",
      "1979/1979 [==============================] - 0s 73us/step - loss: 0.3867 - accuracy: 0.9384\n",
      "Epoch 61/150\n",
      "1979/1979 [==============================] - 0s 80us/step - loss: 0.3806 - accuracy: 0.9404\n",
      "Epoch 62/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.3749 - accuracy: 0.9439\n",
      "Epoch 63/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 0.3689 - accuracy: 0.9464\n",
      "Epoch 64/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.3643 - accuracy: 0.9474\n",
      "Epoch 65/150\n",
      "1979/1979 [==============================] - 0s 90us/step - loss: 0.3579 - accuracy: 0.9454\n",
      "Epoch 66/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 0.3525 - accuracy: 0.9480\n",
      "Epoch 67/150\n",
      "1979/1979 [==============================] - 0s 80us/step - loss: 0.3473 - accuracy: 0.9510\n",
      "Epoch 68/150\n",
      "1979/1979 [==============================] - 0s 75us/step - loss: 0.3430 - accuracy: 0.9469\n",
      "Epoch 69/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.3374 - accuracy: 0.9540\n",
      "Epoch 70/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.3334 - accuracy: 0.9515\n",
      "Epoch 71/150\n",
      "1979/1979 [==============================] - 0s 89us/step - loss: 0.3282 - accuracy: 0.9545\n",
      "Epoch 72/150\n",
      "1979/1979 [==============================] - 0s 87us/step - loss: 0.3249 - accuracy: 0.9525\n",
      "Epoch 73/150\n",
      "1979/1979 [==============================] - 0s 87us/step - loss: 0.3202 - accuracy: 0.9530\n",
      "Epoch 74/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.3158 - accuracy: 0.9540\n",
      "Epoch 75/150\n",
      "1979/1979 [==============================] - 0s 96us/step - loss: 0.3121 - accuracy: 0.9525\n",
      "Epoch 76/150\n",
      "1979/1979 [==============================] - 0s 106us/step - loss: 0.3079 - accuracy: 0.9581\n",
      "Epoch 77/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.3047 - accuracy: 0.9555\n",
      "Epoch 78/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.3010 - accuracy: 0.9576\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979/1979 [==============================] - 0s 98us/step - loss: 0.2967 - accuracy: 0.9576\n",
      "Epoch 80/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.2941 - accuracy: 0.9545\n",
      "Epoch 81/150\n",
      "1979/1979 [==============================] - 0s 100us/step - loss: 0.2902 - accuracy: 0.9565\n",
      "Epoch 82/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 0.2869 - accuracy: 0.9596\n",
      "Epoch 83/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.2837 - accuracy: 0.9586\n",
      "Epoch 84/150\n",
      "1979/1979 [==============================] - 0s 95us/step - loss: 0.2805 - accuracy: 0.9606\n",
      "Epoch 85/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.2778 - accuracy: 0.9591\n",
      "Epoch 86/150\n",
      "1979/1979 [==============================] - 0s 78us/step - loss: 0.2750 - accuracy: 0.9570\n",
      "Epoch 87/150\n",
      "1979/1979 [==============================] - 0s 78us/step - loss: 0.2714 - accuracy: 0.9621\n",
      "Epoch 88/150\n",
      "1979/1979 [==============================] - 0s 89us/step - loss: 0.2687 - accuracy: 0.9611\n",
      "Epoch 89/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.2654 - accuracy: 0.9616\n",
      "Epoch 90/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.2627 - accuracy: 0.9621\n",
      "Epoch 91/150\n",
      "1979/1979 [==============================] - 0s 88us/step - loss: 0.2601 - accuracy: 0.9621\n",
      "Epoch 92/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.2576 - accuracy: 0.9641\n",
      "Epoch 93/150\n",
      "1979/1979 [==============================] - 0s 76us/step - loss: 0.2553 - accuracy: 0.9601\n",
      "Epoch 94/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.2525 - accuracy: 0.9626\n",
      "Epoch 95/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.2510 - accuracy: 0.9672\n",
      "Epoch 96/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.2479 - accuracy: 0.9651\n",
      "Epoch 97/150\n",
      "1979/1979 [==============================] - 0s 75us/step - loss: 0.2460 - accuracy: 0.9631\n",
      "Epoch 98/150\n",
      "1979/1979 [==============================] - 0s 87us/step - loss: 0.2431 - accuracy: 0.9672\n",
      "Epoch 99/150\n",
      "1979/1979 [==============================] - 0s 81us/step - loss: 0.2395 - accuracy: 0.9677\n",
      "Epoch 100/150\n",
      "1979/1979 [==============================] - 0s 87us/step - loss: 0.2386 - accuracy: 0.9626\n",
      "Epoch 101/150\n",
      "1979/1979 [==============================] - 1s 266us/step - loss: 0.2365 - accuracy: 0.9672\n",
      "Epoch 102/150\n",
      "1979/1979 [==============================] - 0s 233us/step - loss: 0.2345 - accuracy: 0.9666\n",
      "Epoch 103/150\n",
      "1979/1979 [==============================] - 0s 240us/step - loss: 0.2328 - accuracy: 0.9666\n",
      "Epoch 104/150\n",
      "1979/1979 [==============================] - 0s 203us/step - loss: 0.2301 - accuracy: 0.9666\n",
      "Epoch 105/150\n",
      "1979/1979 [==============================] - 0s 207us/step - loss: 0.2283 - accuracy: 0.9661\n",
      "Epoch 106/150\n",
      "1979/1979 [==============================] - 0s 221us/step - loss: 0.2263 - accuracy: 0.9682\n",
      "Epoch 107/150\n",
      "1979/1979 [==============================] - 1s 259us/step - loss: 0.2244 - accuracy: 0.9687\n",
      "Epoch 108/150\n",
      "1979/1979 [==============================] - 0s 196us/step - loss: 0.2220 - accuracy: 0.9687\n",
      "Epoch 109/150\n",
      "1979/1979 [==============================] - 1s 266us/step - loss: 0.2208 - accuracy: 0.9697\n",
      "Epoch 110/150\n",
      "1979/1979 [==============================] - 1s 259us/step - loss: 0.2185 - accuracy: 0.9717\n",
      "Epoch 111/150\n",
      "1979/1979 [==============================] - 0s 200us/step - loss: 0.2167 - accuracy: 0.9692\n",
      "Epoch 112/150\n",
      "1979/1979 [==============================] - 0s 213us/step - loss: 0.2149 - accuracy: 0.9687\n",
      "Epoch 113/150\n",
      "1979/1979 [==============================] - 0s 227us/step - loss: 0.2131 - accuracy: 0.9712\n",
      "Epoch 114/150\n",
      "1979/1979 [==============================] - 0s 202us/step - loss: 0.2118 - accuracy: 0.9672\n",
      "Epoch 115/150\n",
      "1979/1979 [==============================] - 0s 244us/step - loss: 0.2101 - accuracy: 0.9732\n",
      "Epoch 116/150\n",
      "1979/1979 [==============================] - 0s 221us/step - loss: 0.2082 - accuracy: 0.9707\n",
      "Epoch 117/150\n",
      "1979/1979 [==============================] - 0s 238us/step - loss: 0.2062 - accuracy: 0.9712\n",
      "Epoch 118/150\n",
      "1979/1979 [==============================] - 0s 212us/step - loss: 0.2050 - accuracy: 0.9717\n",
      "Epoch 119/150\n",
      "1979/1979 [==============================] - 0s 212us/step - loss: 0.2029 - accuracy: 0.9697\n",
      "Epoch 120/150\n",
      "1979/1979 [==============================] - 0s 236us/step - loss: 0.2022 - accuracy: 0.9732\n",
      "Epoch 121/150\n",
      "1979/1979 [==============================] - 0s 153us/step - loss: 0.2008 - accuracy: 0.9702\n",
      "Epoch 122/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.1985 - accuracy: 0.9722\n",
      "Epoch 123/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.1978 - accuracy: 0.9742\n",
      "Epoch 124/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.1957 - accuracy: 0.9747\n",
      "Epoch 125/150\n",
      "1979/1979 [==============================] - 0s 80us/step - loss: 0.1937 - accuracy: 0.9722\n",
      "Epoch 126/150\n",
      "1979/1979 [==============================] - 0s 76us/step - loss: 0.1930 - accuracy: 0.9757\n",
      "Epoch 127/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 0.1916 - accuracy: 0.9737\n",
      "Epoch 128/150\n",
      "1979/1979 [==============================] - 0s 84us/step - loss: 0.1896 - accuracy: 0.9742\n",
      "Epoch 129/150\n",
      "1979/1979 [==============================] - 0s 85us/step - loss: 0.1892 - accuracy: 0.9737\n",
      "Epoch 130/150\n",
      "1979/1979 [==============================] - 0s 73us/step - loss: 0.1876 - accuracy: 0.9737\n",
      "Epoch 131/150\n",
      "1979/1979 [==============================] - 0s 78us/step - loss: 0.1861 - accuracy: 0.9722\n",
      "Epoch 132/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.1843 - accuracy: 0.9742\n",
      "Epoch 133/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.1832 - accuracy: 0.9747\n",
      "Epoch 134/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 0.1829 - accuracy: 0.9747\n",
      "Epoch 135/150\n",
      "1979/1979 [==============================] - 0s 77us/step - loss: 0.1813 - accuracy: 0.9752\n",
      "Epoch 136/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 0.1798 - accuracy: 0.9737\n",
      "Epoch 137/150\n",
      "1979/1979 [==============================] - 0s 83us/step - loss: 0.1785 - accuracy: 0.9747\n",
      "Epoch 138/150\n",
      "1979/1979 [==============================] - 0s 74us/step - loss: 0.1772 - accuracy: 0.9742\n",
      "Epoch 139/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.1760 - accuracy: 0.9757\n",
      "Epoch 140/150\n",
      "1979/1979 [==============================] - 0s 79us/step - loss: 0.1753 - accuracy: 0.9747\n",
      "Epoch 141/150\n",
      "1979/1979 [==============================] - 0s 89us/step - loss: 0.1736 - accuracy: 0.9752\n",
      "Epoch 142/150\n",
      "1979/1979 [==============================] - 0s 88us/step - loss: 0.1733 - accuracy: 0.9727\n",
      "Epoch 143/150\n",
      "1979/1979 [==============================] - 0s 75us/step - loss: 0.1712 - accuracy: 0.9737\n",
      "Epoch 144/150\n",
      "1979/1979 [==============================] - 0s 76us/step - loss: 0.1698 - accuracy: 0.9768\n",
      "Epoch 145/150\n",
      "1979/1979 [==============================] - 0s 85us/step - loss: 0.1702 - accuracy: 0.9732\n",
      "Epoch 146/150\n",
      "1979/1979 [==============================] - 0s 75us/step - loss: 0.1681 - accuracy: 0.9757\n",
      "Epoch 147/150\n",
      "1979/1979 [==============================] - 0s 74us/step - loss: 0.1669 - accuracy: 0.9783\n",
      "Epoch 148/150\n",
      "1979/1979 [==============================] - 0s 82us/step - loss: 0.1659 - accuracy: 0.9742\n",
      "Epoch 149/150\n",
      "1979/1979 [==============================] - 0s 80us/step - loss: 0.1646 - accuracy: 0.9768\n",
      "Epoch 150/150\n",
      "1979/1979 [==============================] - 0s 86us/step - loss: 0.1633 - accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13cb0dd10>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for column in X_test:\n",
    "    sample_X = column.reshape(1,18)\n",
    "    preds.append(np.argmax(model.predict(sample_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  -2.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., -24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  -3.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  -6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  -3.,   0.,   0.,   0.,   0.,   0., -13.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  -3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   2.,   2.,   0.,   0., -23.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -23.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  -2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  -4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -10.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., -19.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -10.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -10.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = preds - y_test\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "25.0\n",
      "20.0\n",
      "9.0\n",
      "20.0\n",
      "17.0\n",
      "4.0\n",
      "2.0\n",
      "6.0\n",
      "20.0\n",
      "10.0\n",
      "4.0\n",
      "4.0\n",
      "25.0\n",
      "25.0\n",
      "7.0\n",
      "4.0\n",
      "10.0\n",
      "14.0\n",
      "19.0\n",
      "14.0\n",
      "8.0\n",
      "14.0\n",
      "23 975\n"
     ]
    }
   ],
   "source": [
    "wrong = 0\n",
    "for i in range(0, len(acc)):\n",
    "    if acc[i] != 0:\n",
    "        wrong += 1\n",
    "        print(y_test[i])\n",
    "print(wrong, len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('epic_num_reader.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
