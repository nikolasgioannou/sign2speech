{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abcd\n",
    "collinX1 = loadtxt('data/collin_data_1.txt', delimiter=',')\n",
    "collinY1 = loadtxt('labels/collin_labels_1.txt', delimiter=',')\n",
    "\n",
    "# abcd\n",
    "tianX2 = loadtxt('data/tian_data_2.txt', delimiter=',')\n",
    "tianY2 = loadtxt('labels/tian_labels_2.txt', delimiter=',')\n",
    "\n",
    "# efgh\n",
    "nikolasX3 = loadtxt('data/nikolas_data_3.txt', delimiter=',')\n",
    "nikolasY3 = loadtxt('labels/nikolas_labels_3.txt', delimiter=',')\n",
    "\n",
    "# ijkl\n",
    "tianX4 = loadtxt('data/tian_data_4.txt', delimiter=',')\n",
    "tianY4 = loadtxt('labels/tian_labels_4.txt', delimiter=',')\n",
    "\n",
    "# mnop\n",
    "tianX5 = loadtxt('data/tian_data_5.txt', delimiter=',')\n",
    "tianY5 = loadtxt('labels/tian_labels_5.txt', delimiter=',')\n",
    "\n",
    "# qrst\n",
    "tianX6 = loadtxt('data/tian_data_6.txt', delimiter=',')\n",
    "tianY6 = loadtxt('labels/tian_labels_6.txt', delimiter=',')\n",
    "\n",
    "# uvwxyz\n",
    "tianX7 = loadtxt('data/tian_data_7.txt', delimiter=',')\n",
    "tianY7 = loadtxt('labels/tian_labels_7.txt', delimiter=',')\n",
    "\n",
    "# efgh\n",
    "tianX8 = loadtxt('data/tian_data_8.txt', delimiter=',')\n",
    "tianY8 = loadtxt('labels/tian_labels_8.txt', delimiter=',')\n",
    "\n",
    "# s rest pujt\n",
    "tianX9 = loadtxt('data/tian_data_9.txt', delimiter=',')\n",
    "tianY9 = loadtxt('labels/tian_labels_9.txt', delimiter=',')\n",
    "\n",
    "# drjel\n",
    "tianX10 = loadtxt('data/tian_data_10.txt', delimiter=',')\n",
    "tianY10 = loadtxt('labels/tian_labels_10.txt', delimiter=',')\n",
    "\n",
    "# jz back rest\n",
    "tianX11 = loadtxt('data/tian_data_11.txt', delimiter=',')\n",
    "tianY11 = loadtxt('labels/tian_labels_11.txt', delimiter=',')\n",
    "\n",
    "X = np.concatenate((collinX1, tianX2, nikolasX3, tianX4, tianX5, tianX6, tianX7, tianX8, tianX9, tianX10, tianX11), axis=0)\n",
    "y = np.concatenate((collinY1, tianY2, nikolasY3, tianY4, tianY5, tianY6, tianY7, tianY8, tianY9, tianY10, tianY11), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0     189\n",
       "9.0     159\n",
       "4.0     138\n",
       "17.0    125\n",
       "2.0     121\n",
       "1.0     119\n",
       "0.0     117\n",
       "11.0    111\n",
       "7.0      96\n",
       "6.0      89\n",
       "5.0      82\n",
       "26.0     82\n",
       "18.0     72\n",
       "19.0     70\n",
       "25.0     69\n",
       "12.0     62\n",
       "15.0     60\n",
       "13.0     53\n",
       "20.0     52\n",
       "27.0     52\n",
       "8.0      52\n",
       "16.0     51\n",
       "10.0     50\n",
       "14.0     43\n",
       "23.0     40\n",
       "24.0     35\n",
       "21.0     33\n",
       "22.0     25\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=18, activation='relu'))\n",
    "model.add(Dense(28, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2247/2247 [==============================] - 0s 122us/step - loss: 3.2761 - accuracy: 0.0632\n",
      "Epoch 2/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 3.1244 - accuracy: 0.1397\n",
      "Epoch 3/150\n",
      "2247/2247 [==============================] - 0s 88us/step - loss: 2.9992 - accuracy: 0.2336\n",
      "Epoch 4/150\n",
      "2247/2247 [==============================] - 0s 96us/step - loss: 2.8677 - accuracy: 0.2879\n",
      "Epoch 5/150\n",
      "2247/2247 [==============================] - 0s 83us/step - loss: 2.7281 - accuracy: 0.3164\n",
      "Epoch 6/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 2.5844 - accuracy: 0.3609\n",
      "Epoch 7/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 2.4439 - accuracy: 0.3983\n",
      "Epoch 8/150\n",
      "2247/2247 [==============================] - 0s 77us/step - loss: 2.3109 - accuracy: 0.4215\n",
      "Epoch 9/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 2.1866 - accuracy: 0.4401\n",
      "Epoch 10/150\n",
      "2247/2247 [==============================] - 0s 89us/step - loss: 2.0723 - accuracy: 0.4700\n",
      "Epoch 11/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 1.9643 - accuracy: 0.4918\n",
      "Epoch 12/150\n",
      "2247/2247 [==============================] - 0s 86us/step - loss: 1.8648 - accuracy: 0.5154\n",
      "Epoch 13/150\n",
      "2247/2247 [==============================] - 0s 93us/step - loss: 1.7719 - accuracy: 0.5487\n",
      "Epoch 14/150\n",
      "2247/2247 [==============================] - 0s 106us/step - loss: 1.6868 - accuracy: 0.5785\n",
      "Epoch 15/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 1.6060 - accuracy: 0.5834\n",
      "Epoch 16/150\n",
      "2247/2247 [==============================] - 0s 87us/step - loss: 1.5318 - accuracy: 0.6133\n",
      "Epoch 17/150\n",
      "2247/2247 [==============================] - 0s 97us/step - loss: 1.4624 - accuracy: 0.6324\n",
      "Epoch 18/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 1.3967 - accuracy: 0.6604\n",
      "Epoch 19/150\n",
      "2247/2247 [==============================] - 0s 87us/step - loss: 1.3368 - accuracy: 0.6809\n",
      "Epoch 20/150\n",
      "2247/2247 [==============================] - 0s 83us/step - loss: 1.2798 - accuracy: 0.7063\n",
      "Epoch 21/150\n",
      "2247/2247 [==============================] - 0s 107us/step - loss: 1.2279 - accuracy: 0.7072\n",
      "Epoch 22/150\n",
      "2247/2247 [==============================] - 0s 98us/step - loss: 1.1778 - accuracy: 0.7530\n",
      "Epoch 23/150\n",
      "2247/2247 [==============================] - 0s 102us/step - loss: 1.1320 - accuracy: 0.7508\n",
      "Epoch 24/150\n",
      "2247/2247 [==============================] - 0s 94us/step - loss: 1.0878 - accuracy: 0.7793\n",
      "Epoch 25/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 1.0482 - accuracy: 0.7922\n",
      "Epoch 26/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 1.0117 - accuracy: 0.8046\n",
      "Epoch 27/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.9764 - accuracy: 0.8117\n",
      "Epoch 28/150\n",
      "2247/2247 [==============================] - 0s 83us/step - loss: 0.9428 - accuracy: 0.8336\n",
      "Epoch 29/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.9121 - accuracy: 0.8358\n",
      "Epoch 30/150\n",
      "2247/2247 [==============================] - 0s 99us/step - loss: 0.8832 - accuracy: 0.8318\n",
      "Epoch 31/150\n",
      "2247/2247 [==============================] - 0s 85us/step - loss: 0.8571 - accuracy: 0.8531\n",
      "Epoch 32/150\n",
      "2247/2247 [==============================] - 0s 84us/step - loss: 0.8304 - accuracy: 0.8514\n",
      "Epoch 33/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.8054 - accuracy: 0.8594\n",
      "Epoch 34/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.7833 - accuracy: 0.8660\n",
      "Epoch 35/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 0.7618 - accuracy: 0.8629\n",
      "Epoch 36/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.7405 - accuracy: 0.8727\n",
      "Epoch 37/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 0.7213 - accuracy: 0.8727\n",
      "Epoch 38/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.7031 - accuracy: 0.8767\n",
      "Epoch 39/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 0.6849 - accuracy: 0.8785\n",
      "Epoch 40/150\n",
      "2247/2247 [==============================] - 0s 84us/step - loss: 0.6677 - accuracy: 0.8830\n",
      "Epoch 41/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.6486 - accuracy: 0.8856\n",
      "Epoch 42/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.6274 - accuracy: 0.8887\n",
      "Epoch 43/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.6088 - accuracy: 0.8901\n",
      "Epoch 44/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 0.5892 - accuracy: 0.8945\n",
      "Epoch 45/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 0.5729 - accuracy: 0.9034\n",
      "Epoch 46/150\n",
      "2247/2247 [==============================] - 0s 84us/step - loss: 0.5551 - accuracy: 0.9070\n",
      "Epoch 47/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.5410 - accuracy: 0.9048\n",
      "Epoch 48/150\n",
      "2247/2247 [==============================] - 0s 86us/step - loss: 0.5249 - accuracy: 0.9097\n",
      "Epoch 49/150\n",
      "2247/2247 [==============================] - 0s 87us/step - loss: 0.5119 - accuracy: 0.9114\n",
      "Epoch 50/150\n",
      "2247/2247 [==============================] - 0s 106us/step - loss: 0.4980 - accuracy: 0.9199\n",
      "Epoch 51/150\n",
      "2247/2247 [==============================] - 0s 109us/step - loss: 0.4846 - accuracy: 0.9159\n",
      "Epoch 52/150\n",
      "2247/2247 [==============================] - 0s 105us/step - loss: 0.4735 - accuracy: 0.9221\n",
      "Epoch 53/150\n",
      "2247/2247 [==============================] - 0s 114us/step - loss: 0.4613 - accuracy: 0.9252\n",
      "Epoch 54/150\n",
      "2247/2247 [==============================] - 0s 90us/step - loss: 0.4516 - accuracy: 0.9239\n",
      "Epoch 55/150\n",
      "2247/2247 [==============================] - 0s 119us/step - loss: 0.4396 - accuracy: 0.9257\n",
      "Epoch 56/150\n",
      "2247/2247 [==============================] - 0s 86us/step - loss: 0.4304 - accuracy: 0.9319\n",
      "Epoch 57/150\n",
      "2247/2247 [==============================] - 0s 108us/step - loss: 0.4217 - accuracy: 0.9288\n",
      "Epoch 58/150\n",
      "2247/2247 [==============================] - 0s 88us/step - loss: 0.4113 - accuracy: 0.9337\n",
      "Epoch 59/150\n",
      "2247/2247 [==============================] - 0s 117us/step - loss: 0.4026 - accuracy: 0.93590s - loss: 0.3856 - accura\n",
      "Epoch 60/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 0.3943 - accuracy: 0.9341\n",
      "Epoch 61/150\n",
      "2247/2247 [==============================] - 0s 103us/step - loss: 0.3865 - accuracy: 0.9413\n",
      "Epoch 62/150\n",
      "2247/2247 [==============================] - 0s 93us/step - loss: 0.3802 - accuracy: 0.9399\n",
      "Epoch 63/150\n",
      "2247/2247 [==============================] - 0s 107us/step - loss: 0.3731 - accuracy: 0.9421\n",
      "Epoch 64/150\n",
      "2247/2247 [==============================] - 0s 156us/step - loss: 0.3663 - accuracy: 0.94260s - loss: 0.3766 - accuracy: 0.\n",
      "Epoch 65/150\n",
      "2247/2247 [==============================] - 0s 95us/step - loss: 0.3597 - accuracy: 0.9421\n",
      "Epoch 66/150\n",
      "2247/2247 [==============================] - 0s 93us/step - loss: 0.3542 - accuracy: 0.9470\n",
      "Epoch 67/150\n",
      "2247/2247 [==============================] - 0s 84us/step - loss: 0.3470 - accuracy: 0.9497\n",
      "Epoch 68/150\n",
      "2247/2247 [==============================] - 0s 84us/step - loss: 0.3414 - accuracy: 0.9479\n",
      "Epoch 69/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.3351 - accuracy: 0.9502\n",
      "Epoch 70/150\n",
      "2247/2247 [==============================] - 0s 83us/step - loss: 0.3299 - accuracy: 0.9488\n",
      "Epoch 71/150\n",
      "2247/2247 [==============================] - 0s 87us/step - loss: 0.3247 - accuracy: 0.9488\n",
      "Epoch 72/150\n",
      "2247/2247 [==============================] - 0s 87us/step - loss: 0.3196 - accuracy: 0.9551\n",
      "Epoch 73/150\n",
      "2247/2247 [==============================] - 0s 95us/step - loss: 0.3156 - accuracy: 0.9533\n",
      "Epoch 74/150\n",
      "2247/2247 [==============================] - 0s 84us/step - loss: 0.3097 - accuracy: 0.9577\n",
      "Epoch 75/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 0.3055 - accuracy: 0.9595\n",
      "Epoch 76/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.3013 - accuracy: 0.9577\n",
      "Epoch 77/150\n",
      "2247/2247 [==============================] - 0s 85us/step - loss: 0.2973 - accuracy: 0.9582\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2247/2247 [==============================] - 0s 94us/step - loss: 0.2927 - accuracy: 0.9608\n",
      "Epoch 79/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2892 - accuracy: 0.9604\n",
      "Epoch 80/150\n",
      "2247/2247 [==============================] - 0s 75us/step - loss: 0.2849 - accuracy: 0.9626\n",
      "Epoch 81/150\n",
      "2247/2247 [==============================] - 0s 76us/step - loss: 0.2823 - accuracy: 0.9613\n",
      "Epoch 82/150\n",
      "2247/2247 [==============================] - 0s 77us/step - loss: 0.2779 - accuracy: 0.9617\n",
      "Epoch 83/150\n",
      "2247/2247 [==============================] - 0s 75us/step - loss: 0.2744 - accuracy: 0.9631\n",
      "Epoch 84/150\n",
      "2247/2247 [==============================] - 0s 76us/step - loss: 0.2703 - accuracy: 0.9622\n",
      "Epoch 85/150\n",
      "2247/2247 [==============================] - 0s 83us/step - loss: 0.2671 - accuracy: 0.9648\n",
      "Epoch 86/150\n",
      "2247/2247 [==============================] - 0s 75us/step - loss: 0.2646 - accuracy: 0.9640\n",
      "Epoch 87/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2618 - accuracy: 0.9635\n",
      "Epoch 88/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2572 - accuracy: 0.9662\n",
      "Epoch 89/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 0.2556 - accuracy: 0.9635\n",
      "Epoch 90/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 0.2520 - accuracy: 0.9657\n",
      "Epoch 91/150\n",
      "2247/2247 [==============================] - 0s 77us/step - loss: 0.2496 - accuracy: 0.9648\n",
      "Epoch 92/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2469 - accuracy: 0.9657\n",
      "Epoch 93/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.2431 - accuracy: 0.9666\n",
      "Epoch 94/150\n",
      "2247/2247 [==============================] - 0s 77us/step - loss: 0.2411 - accuracy: 0.9675\n",
      "Epoch 95/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2395 - accuracy: 0.9662\n",
      "Epoch 96/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.2349 - accuracy: 0.9666\n",
      "Epoch 97/150\n",
      "2247/2247 [==============================] - 0s 77us/step - loss: 0.2328 - accuracy: 0.9729\n",
      "Epoch 98/150\n",
      "2247/2247 [==============================] - 0s 86us/step - loss: 0.2315 - accuracy: 0.9671\n",
      "Epoch 99/150\n",
      "2247/2247 [==============================] - 0s 75us/step - loss: 0.2284 - accuracy: 0.9644\n",
      "Epoch 100/150\n",
      "2247/2247 [==============================] - 0s 76us/step - loss: 0.2255 - accuracy: 0.9684\n",
      "Epoch 101/150\n",
      "2247/2247 [==============================] - 0s 83us/step - loss: 0.2230 - accuracy: 0.9688\n",
      "Epoch 102/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.2213 - accuracy: 0.9706\n",
      "Epoch 103/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.2195 - accuracy: 0.9684\n",
      "Epoch 104/150\n",
      "2247/2247 [==============================] - 0s 84us/step - loss: 0.2168 - accuracy: 0.9711\n",
      "Epoch 105/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.2145 - accuracy: 0.9688\n",
      "Epoch 106/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2132 - accuracy: 0.9724\n",
      "Epoch 107/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.2106 - accuracy: 0.9697\n",
      "Epoch 108/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2082 - accuracy: 0.9706\n",
      "Epoch 109/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2064 - accuracy: 0.9702\n",
      "Epoch 110/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.2037 - accuracy: 0.9715\n",
      "Epoch 111/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 0.2027 - accuracy: 0.9715\n",
      "Epoch 112/150\n",
      "2247/2247 [==============================] - 0s 103us/step - loss: 0.2015 - accuracy: 0.9715\n",
      "Epoch 113/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1983 - accuracy: 0.9711\n",
      "Epoch 114/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1965 - accuracy: 0.9737\n",
      "Epoch 115/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1951 - accuracy: 0.9737\n",
      "Epoch 116/150\n",
      "2247/2247 [==============================] - 0s 77us/step - loss: 0.1931 - accuracy: 0.9729\n",
      "Epoch 117/150\n",
      "2247/2247 [==============================] - 0s 76us/step - loss: 0.1923 - accuracy: 0.9724\n",
      "Epoch 118/150\n",
      "2247/2247 [==============================] - 0s 100us/step - loss: 0.1903 - accuracy: 0.9737\n",
      "Epoch 119/150\n",
      "2247/2247 [==============================] - 0s 105us/step - loss: 0.1895 - accuracy: 0.9751\n",
      "Epoch 120/150\n",
      "2247/2247 [==============================] - 0s 72us/step - loss: 0.1871 - accuracy: 0.9760\n",
      "Epoch 121/150\n",
      "2247/2247 [==============================] - 0s 75us/step - loss: 0.1857 - accuracy: 0.9764\n",
      "Epoch 122/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1831 - accuracy: 0.9733\n",
      "Epoch 123/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.1817 - accuracy: 0.9746\n",
      "Epoch 124/150\n",
      "2247/2247 [==============================] - 0s 75us/step - loss: 0.1802 - accuracy: 0.9760\n",
      "Epoch 125/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.1790 - accuracy: 0.9755\n",
      "Epoch 126/150\n",
      "2247/2247 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.97 - 0s 78us/step - loss: 0.1782 - accuracy: 0.9764\n",
      "Epoch 127/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.1771 - accuracy: 0.9760\n",
      "Epoch 128/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 0.1759 - accuracy: 0.9760\n",
      "Epoch 129/150\n",
      "2247/2247 [==============================] - 0s 81us/step - loss: 0.1738 - accuracy: 0.9760\n",
      "Epoch 130/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.1720 - accuracy: 0.9764\n",
      "Epoch 131/150\n",
      "2247/2247 [==============================] - 0s 85us/step - loss: 0.1714 - accuracy: 0.9760\n",
      "Epoch 132/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.1698 - accuracy: 0.9760\n",
      "Epoch 133/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.1682 - accuracy: 0.9751\n",
      "Epoch 134/150\n",
      "2247/2247 [==============================] - 0s 82us/step - loss: 0.1668 - accuracy: 0.9755\n",
      "Epoch 135/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.1651 - accuracy: 0.9760\n",
      "Epoch 136/150\n",
      "2247/2247 [==============================] - 0s 79us/step - loss: 0.1637 - accuracy: 0.9795\n",
      "Epoch 137/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.1628 - accuracy: 0.9760\n",
      "Epoch 138/150\n",
      "2247/2247 [==============================] - 0s 78us/step - loss: 0.1620 - accuracy: 0.9769\n",
      "Epoch 139/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 0.1611 - accuracy: 0.9782\n",
      "Epoch 140/150\n",
      "2247/2247 [==============================] - 0s 80us/step - loss: 0.1594 - accuracy: 0.9764\n",
      "Epoch 141/150\n",
      "2247/2247 [==============================] - 0s 126us/step - loss: 0.1584 - accuracy: 0.9777\n",
      "Epoch 142/150\n",
      "2247/2247 [==============================] - 0s 130us/step - loss: 0.1571 - accuracy: 0.9777\n",
      "Epoch 143/150\n",
      "2247/2247 [==============================] - 0s 103us/step - loss: 0.1559 - accuracy: 0.9773\n",
      "Epoch 144/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1550 - accuracy: 0.9795\n",
      "Epoch 145/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1532 - accuracy: 0.9773\n",
      "Epoch 146/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1529 - accuracy: 0.9786\n",
      "Epoch 147/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1516 - accuracy: 0.9777\n",
      "Epoch 148/150\n",
      "2247/2247 [==============================] - 0s 75us/step - loss: 0.1502 - accuracy: 0.9777\n",
      "Epoch 149/150\n",
      "2247/2247 [==============================] - 0s 74us/step - loss: 0.1495 - accuracy: 0.9795\n",
      "Epoch 150/150\n",
      "2247/2247 [==============================] - 0s 73us/step - loss: 0.1491 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x139625050>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for column in X_test:\n",
    "    sample_X = column.reshape(1,18)\n",
    "    preds.append(np.argmax(model.predict(sample_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = preds - y_test\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "17.0\n",
      "20.0\n",
      "4.0\n",
      "14.0\n",
      "20.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "21.0\n",
      "11.0\n",
      "14.0\n",
      "0.0\n",
      "20.0\n",
      "26.0\n",
      "11.0\n",
      "4.0\n",
      "14.0\n",
      "11.0\n",
      "6.0\n",
      "4.0\n",
      "17.0\n",
      "10.0\n",
      "20.0\n",
      "1.0\n",
      "10.0\n",
      "22.0\n",
      "20.0\n",
      "4.0\n",
      "11.0\n",
      "3.0\n",
      "20.0\n",
      "3.0\n",
      "23.0\n",
      "34 1108\n"
     ]
    }
   ],
   "source": [
    "wrong = 0\n",
    "for i in range(0, len(acc)):\n",
    "    if acc[i] != 0:\n",
    "        wrong += 1\n",
    "        print(y_test[i])\n",
    "print(wrong, len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('epic_num_reader.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
