{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abcd\n",
    "collinX1 = loadtxt('data/collin_data_1.txt', delimiter=',')\n",
    "collinY1 = loadtxt('labels/collin_labels_1.txt', delimiter=',')\n",
    "\n",
    "# abcd\n",
    "tianX2 = loadtxt('data/tian_data_2.txt', delimiter=',')\n",
    "tianY2 = loadtxt('labels/tian_labels_2.txt', delimiter=',')\n",
    "\n",
    "# efgh\n",
    "nikolasX3 = loadtxt('data/nikolas_data_3.txt', delimiter=',')\n",
    "nikolasY3 = loadtxt('labels/nikolas_labels_3.txt', delimiter=',')\n",
    "\n",
    "# ijkl\n",
    "tianX4 = loadtxt('data/tian_data_4.txt', delimiter=',')\n",
    "tianY4 = loadtxt('labels/tian_labels_4.txt', delimiter=',')\n",
    "\n",
    "# mnop\n",
    "tianX5 = loadtxt('data/tian_data_5.txt', delimiter=',')\n",
    "tianY5 = loadtxt('labels/tian_labels_5.txt', delimiter=',')\n",
    "\n",
    "# qrst\n",
    "tianX6 = loadtxt('data/tian_data_6.txt', delimiter=',')\n",
    "tianY6 = loadtxt('labels/tian_labels_6.txt', delimiter=',')\n",
    "\n",
    "# uvwxyz\n",
    "tianX7 = loadtxt('data/tian_data_7.txt', delimiter=',')\n",
    "tianY7 = loadtxt('labels/tian_labels_7.txt', delimiter=',')\n",
    "\n",
    "# efgh\n",
    "tianX8 = loadtxt('data/tian_data_8.txt', delimiter=',')\n",
    "tianY8 = loadtxt('labels/tian_labels_8.txt', delimiter=',')\n",
    "\n",
    "# s rest pujt\n",
    "tianX9 = loadtxt('data/tian_data_9.txt', delimiter=',')\n",
    "tianY9 = loadtxt('labels/tian_labels_9.txt', delimiter=',')\n",
    "\n",
    "# drjel\n",
    "tianX10 = loadtxt('data/tian_data_10.txt', delimiter=',')\n",
    "tianY10 = loadtxt('labels/tian_labels_10.txt', delimiter=',')\n",
    "\n",
    "# jz back rest\n",
    "tianX11 = loadtxt('data/tian_data_11.txt', delimiter=',')\n",
    "tianY11 = loadtxt('labels/tian_labels_11.txt', delimiter=',')\n",
    "\n",
    "# ode home\n",
    "tianX12 = loadtxt('data/tian_data_12.txt', delimiter=',')\n",
    "tianY12 = loadtxt('labels/tian_labels_12.txt', delimiter=',')\n",
    "\n",
    "X = np.concatenate((collinX1, tianX2, nikolasX3, tianX4, tianX5, tianX6, tianX7, tianX8, tianX9, tianX10, tianX11, tianX12), axis=0)\n",
    "y = np.concatenate((collinY1, tianY2, nikolasY3, tianY4, tianY5, tianY6, tianY7, tianY8, tianY9, tianY10, tianY11, tianY12), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0     258\n",
       "4.0     229\n",
       "9.0     168\n",
       "0.0     128\n",
       "14.0    126\n",
       "17.0    121\n",
       "11.0    118\n",
       "2.0     113\n",
       "1.0     112\n",
       "7.0      90\n",
       "6.0      85\n",
       "5.0      85\n",
       "26.0     80\n",
       "28.0     77\n",
       "18.0     70\n",
       "25.0     70\n",
       "15.0     63\n",
       "19.0     61\n",
       "12.0     60\n",
       "10.0     58\n",
       "16.0     57\n",
       "8.0      55\n",
       "27.0     55\n",
       "13.0     50\n",
       "20.0     48\n",
       "23.0     43\n",
       "24.0     38\n",
       "21.0     36\n",
       "22.0     29\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=18, activation='relu'))\n",
    "model.add(Dense(29, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2583/2583 [==============================] - 0s 114us/step - loss: 3.3117 - accuracy: 0.0650\n",
      "Epoch 2/150\n",
      "2583/2583 [==============================] - 0s 86us/step - loss: 3.1576 - accuracy: 0.1165\n",
      "Epoch 3/150\n",
      "2583/2583 [==============================] - 0s 83us/step - loss: 3.0462 - accuracy: 0.1618\n",
      "Epoch 4/150\n",
      "2583/2583 [==============================] - 0s 87us/step - loss: 2.9412 - accuracy: 0.1831\n",
      "Epoch 5/150\n",
      "2583/2583 [==============================] - 0s 82us/step - loss: 2.8268 - accuracy: 0.1967\n",
      "Epoch 6/150\n",
      "2583/2583 [==============================] - 0s 95us/step - loss: 2.7085 - accuracy: 0.1843\n",
      "Epoch 7/150\n",
      "2583/2583 [==============================] - 0s 81us/step - loss: 2.5890 - accuracy: 0.2106\n",
      "Epoch 8/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 2.4716 - accuracy: 0.2396\n",
      "Epoch 9/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 2.3560 - accuracy: 0.3012\n",
      "Epoch 10/150\n",
      "2583/2583 [==============================] - 0s 82us/step - loss: 2.2400 - accuracy: 0.3523\n",
      "Epoch 11/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 2.1223 - accuracy: 0.3813\n",
      "Epoch 12/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 2.0078 - accuracy: 0.4568\n",
      "Epoch 13/150\n",
      "2583/2583 [==============================] - 0s 90us/step - loss: 1.8936 - accuracy: 0.5145\n",
      "Epoch 14/150\n",
      "2583/2583 [==============================] - 0s 86us/step - loss: 1.7852 - accuracy: 0.5583\n",
      "Epoch 15/150\n",
      "2583/2583 [==============================] - 0s 82us/step - loss: 1.6856 - accuracy: 0.5772\n",
      "Epoch 16/150\n",
      "2583/2583 [==============================] - 0s 97us/step - loss: 1.5923 - accuracy: 0.5834\n",
      "Epoch 17/150\n",
      "2583/2583 [==============================] - 0s 99us/step - loss: 1.5081 - accuracy: 0.6086\n",
      "Epoch 18/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 1.4326 - accuracy: 0.6268\n",
      "Epoch 19/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 1.3640 - accuracy: 0.6465\n",
      "Epoch 20/150\n",
      "2583/2583 [==============================] - 0s 86us/step - loss: 1.3022 - accuracy: 0.6605\n",
      "Epoch 21/150\n",
      "2583/2583 [==============================] - 0s 85us/step - loss: 1.2459 - accuracy: 0.6694\n",
      "Epoch 22/150\n",
      "2583/2583 [==============================] - 0s 82us/step - loss: 1.1940 - accuracy: 0.6771\n",
      "Epoch 23/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 1.1483 - accuracy: 0.6961\n",
      "Epoch 24/150\n",
      "2583/2583 [==============================] - 0s 83us/step - loss: 1.1047 - accuracy: 0.6965\n",
      "Epoch 25/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 1.0650 - accuracy: 0.7213\n",
      "Epoch 26/150\n",
      "2583/2583 [==============================] - 0s 90us/step - loss: 1.0278 - accuracy: 0.7294\n",
      "Epoch 27/150\n",
      "2583/2583 [==============================] - 0s 83us/step - loss: 0.9931 - accuracy: 0.7511\n",
      "Epoch 28/150\n",
      "2583/2583 [==============================] - 0s 105us/step - loss: 0.9609 - accuracy: 0.7580\n",
      "Epoch 29/150\n",
      "2583/2583 [==============================] - 0s 94us/step - loss: 0.9303 - accuracy: 0.7727\n",
      "Epoch 30/150\n",
      "2583/2583 [==============================] - 0s 81us/step - loss: 0.9029 - accuracy: 0.7929\n",
      "Epoch 31/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 0.8757 - accuracy: 0.7998\n",
      "Epoch 32/150\n",
      "2583/2583 [==============================] - 0s 89us/step - loss: 0.8512 - accuracy: 0.8099\n",
      "Epoch 33/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 0.8265 - accuracy: 0.8208\n",
      "Epoch 34/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.8041 - accuracy: 0.8308\n",
      "Epoch 35/150\n",
      "2583/2583 [==============================] - 0s 81us/step - loss: 0.7824 - accuracy: 0.8339\n",
      "Epoch 36/150\n",
      "2583/2583 [==============================] - 0s 81us/step - loss: 0.7610 - accuracy: 0.8533\n",
      "Epoch 37/150\n",
      "2583/2583 [==============================] - 0s 83us/step - loss: 0.7429 - accuracy: 0.8417\n",
      "Epoch 38/150\n",
      "2583/2583 [==============================] - 0s 80us/step - loss: 0.7244 - accuracy: 0.8560\n",
      "Epoch 39/150\n",
      "2583/2583 [==============================] - 0s 81us/step - loss: 0.7068 - accuracy: 0.8618\n",
      "Epoch 40/150\n",
      "2583/2583 [==============================] - 0s 80us/step - loss: 0.6886 - accuracy: 0.8699\n",
      "Epoch 41/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.6743 - accuracy: 0.8738\n",
      "Epoch 42/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 0.6579 - accuracy: 0.8792\n",
      "Epoch 43/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.6436 - accuracy: 0.8889\n",
      "Epoch 44/150\n",
      "2583/2583 [==============================] - 0s 80us/step - loss: 0.6288 - accuracy: 0.8854\n",
      "Epoch 45/150\n",
      "2583/2583 [==============================] - 0s 80us/step - loss: 0.6155 - accuracy: 0.8928\n",
      "Epoch 46/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.6006 - accuracy: 0.8997\n",
      "Epoch 47/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.5885 - accuracy: 0.9021\n",
      "Epoch 48/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.5759 - accuracy: 0.9032\n",
      "Epoch 49/150\n",
      "2583/2583 [==============================] - 0s 83us/step - loss: 0.5646 - accuracy: 0.9063\n",
      "Epoch 50/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 0.5519 - accuracy: 0.9152\n",
      "Epoch 51/150\n",
      "2583/2583 [==============================] - 0s 81us/step - loss: 0.5421 - accuracy: 0.9079\n",
      "Epoch 52/150\n",
      "2583/2583 [==============================] - 0s 82us/step - loss: 0.5308 - accuracy: 0.9137\n",
      "Epoch 53/150\n",
      "2583/2583 [==============================] - 0s 82us/step - loss: 0.5202 - accuracy: 0.9168\n",
      "Epoch 54/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.5098 - accuracy: 0.9168\n",
      "Epoch 55/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.4995 - accuracy: 0.9218\n",
      "Epoch 56/150\n",
      "2583/2583 [==============================] - 0s 81us/step - loss: 0.4913 - accuracy: 0.9245\n",
      "Epoch 57/150\n",
      "2583/2583 [==============================] - 0s 80us/step - loss: 0.4806 - accuracy: 0.9253\n",
      "Epoch 58/150\n",
      "2583/2583 [==============================] - 0s 96us/step - loss: 0.4730 - accuracy: 0.9295\n",
      "Epoch 59/150\n",
      "2583/2583 [==============================] - 0s 91us/step - loss: 0.4640 - accuracy: 0.9292\n",
      "Epoch 60/150\n",
      "2583/2583 [==============================] - 0s 83us/step - loss: 0.4564 - accuracy: 0.9261\n",
      "Epoch 61/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 0.4471 - accuracy: 0.9319\n",
      "Epoch 62/150\n",
      "2583/2583 [==============================] - 0s 84us/step - loss: 0.4393 - accuracy: 0.9307\n",
      "Epoch 63/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.4321 - accuracy: 0.9392\n",
      "Epoch 64/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.4244 - accuracy: 0.9365\n",
      "Epoch 65/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.4179 - accuracy: 0.9388\n",
      "Epoch 66/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.4103 - accuracy: 0.9396\n",
      "Epoch 67/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.4041 - accuracy: 0.9408\n",
      "Epoch 68/150\n",
      "2583/2583 [==============================] - 0s 83us/step - loss: 0.3975 - accuracy: 0.9431\n",
      "Epoch 69/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.3913 - accuracy: 0.9435\n",
      "Epoch 70/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 0.3856 - accuracy: 0.9423\n",
      "Epoch 71/150\n",
      "2583/2583 [==============================] - 0s 80us/step - loss: 0.3797 - accuracy: 0.9458\n",
      "Epoch 72/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.3736 - accuracy: 0.9481\n",
      "Epoch 73/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 0.3676 - accuracy: 0.9462\n",
      "Epoch 74/150\n",
      "2583/2583 [==============================] - 0s 137us/step - loss: 0.3620 - accuracy: 0.9493\n",
      "Epoch 75/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.3569 - accuracy: 0.9489\n",
      "Epoch 76/150\n",
      "2583/2583 [==============================] - 0s 92us/step - loss: 0.3527 - accuracy: 0.9504\n",
      "Epoch 77/150\n",
      "2583/2583 [==============================] - 0s 116us/step - loss: 0.3476 - accuracy: 0.9504\n",
      "Epoch 78/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 0.3429 - accuracy: 0.9508\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.3380 - accuracy: 0.9528\n",
      "Epoch 80/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.3331 - accuracy: 0.9543\n",
      "Epoch 81/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.3289 - accuracy: 0.9539\n",
      "Epoch 82/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.3239 - accuracy: 0.9524\n",
      "Epoch 83/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 0.3194 - accuracy: 0.9543\n",
      "Epoch 84/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.3157 - accuracy: 0.9566\n",
      "Epoch 85/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 0.3121 - accuracy: 0.9555\n",
      "Epoch 86/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.3083 - accuracy: 0.9563\n",
      "Epoch 87/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.3047 - accuracy: 0.9582\n",
      "Epoch 88/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.3014 - accuracy: 0.9559\n",
      "Epoch 89/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.2976 - accuracy: 0.9590\n",
      "Epoch 90/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.2935 - accuracy: 0.9632\n",
      "Epoch 91/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.2916 - accuracy: 0.9578\n",
      "Epoch 92/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.2862 - accuracy: 0.9601\n",
      "Epoch 93/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.2841 - accuracy: 0.9601\n",
      "Epoch 94/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.2805 - accuracy: 0.9621\n",
      "Epoch 95/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.2772 - accuracy: 0.9621\n",
      "Epoch 96/150\n",
      "2583/2583 [==============================] - 0s 77us/step - loss: 0.2758 - accuracy: 0.9613\n",
      "Epoch 97/150\n",
      "2583/2583 [==============================] - 0s 79us/step - loss: 0.2717 - accuracy: 0.9621\n",
      "Epoch 98/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 0.2690 - accuracy: 0.9628\n",
      "Epoch 99/150\n",
      "2583/2583 [==============================] - 0s 78us/step - loss: 0.2664 - accuracy: 0.9648\n",
      "Epoch 100/150\n",
      "2583/2583 [==============================] - 0s 80us/step - loss: 0.2633 - accuracy: 0.9640\n",
      "Epoch 101/150\n",
      "2583/2583 [==============================] - 0s 74us/step - loss: 0.2610 - accuracy: 0.9628\n",
      "Epoch 102/150\n",
      "2583/2583 [==============================] - 0s 76us/step - loss: 0.2586 - accuracy: 0.9632\n",
      "Epoch 103/150\n",
      "2583/2583 [==============================] - 0s 75us/step - loss: 0.2560 - accuracy: 0.9648\n",
      "Epoch 104/150\n",
      "  10/2583 [..............................] - ETA: 0s - loss: 0.3191 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for column in X_test:\n",
    "    sample_X = column.reshape(1,18)\n",
    "    preds.append(np.argmax(model.predict(sample_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = preds - y_test\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = 0\n",
    "for i in range(0, len(acc)):\n",
    "    if acc[i] != 0:\n",
    "        wrong += 1\n",
    "        print(y_test[i])\n",
    "print(wrong, len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('epic_num_reader.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, \"tfjs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
